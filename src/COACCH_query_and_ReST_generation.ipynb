{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d4c7232",
   "metadata": {},
   "source": [
    "# Query COACCH data sets and generate Data Repository [ReST](https://en.wikipedia.org/wiki/ReStructuredText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fee5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodecsv as csv\n",
    "import io\n",
    "import os\n",
    "import urllib\n",
    "import yaml\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Bespoke modules\n",
    "from classes import *\n",
    "from zenodo_helpers import *\n",
    "from rest_helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754845cc",
   "metadata": {},
   "source": [
    "### Query and collect hits from result pages\n",
    "\n",
    "The query string uses [elastic search syntax](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-query-string-query.html#query-string-syntax)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e44cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "# Perform query and collect initial response\n",
    "params = {\n",
    "    'q': urllib.parse.quote(query),\n",
    "    #'type': 'publication',\n",
    "    'type': 'dataset',\n",
    "    'communities': \"coacch-co-designing-the-assessment-of-climate-change-costs-h2020-project\",\n",
    "    'size': 10, # hits per page\n",
    "    'page': 1,\n",
    "    'sort': '-mostrecent',\n",
    "    'access_token': os.environ['ZENODO_API_TOKEN']\n",
    "}\n",
    "response = reget(\"https://zenodo.org/api/records\", params = params)\n",
    "assert response.status_code == 200 # success\n",
    "j = response.json()\n",
    "hits = j['hits']['hits'] # initial set of hits, to be appended to for next pages\n",
    "print(f\"--> {len(hits)}\")\n",
    "hits_total = j['hits']['total']\n",
    "aggregations = j['aggregations']\n",
    "\n",
    "# Process further hits/pages until they exhaust\n",
    "while get_next_link(j): \n",
    "    next_response = reget(get_next_link(j))\n",
    "    assert next_response.status_code == 200 # success\n",
    "    j = next_response.json()\n",
    "    hits.extend(j['hits']['hits'])\n",
    "assert len(hits) == hits_total\n",
    "\n",
    "# Report total hits and ids\n",
    "print(f\"Query resulted in a total of {hits_total} hits with Zenodo IDs:\")\n",
    "pprint([hit['id'] for hit in hits])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8ccbb",
   "metadata": {},
   "source": [
    "### Strip HTML markup from description metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in hits:\n",
    "    hit['metadata']['description'] = strip_html_markup(hit['metadata']['description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14740de",
   "metadata": {},
   "source": [
    "### Download the Zenodo DOI badges as static content\n",
    "\n",
    "So as to not require a separate connection to Zendo for pages to display\n",
    "as well as to make inclusion of badges in the generated PDF work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0fe011",
   "metadata": {},
   "outputs": [],
   "source": [
    "badge_dir = f\"../docs/_static/badges\"\n",
    "if not os.path.exists(badge_dir):\n",
    "    os.makedirs(badge_dir)\n",
    "\n",
    "# List already present badges\n",
    "stale_badges = os.listdir(badge_dir)\n",
    "\n",
    "# Get badges from Zenodo and write them as static content\n",
    "for hit in hits:\n",
    "    badge_url = hit['links']['badge']\n",
    "    badge_name = badge_url.rsplit('/', 1)[-1]\n",
    "    r = reget(badge_url)\n",
    "    with open(f\"{badge_dir}/{badge_name}\", \"wb\") as b:\n",
    "        b.write(r.content)\n",
    "    if badge_name in stale_badges:\n",
    "        # Badge is not stale\n",
    "        stale_badges.remove(badge_name)\n",
    "\n",
    "# Remove any badges that are no longer required\n",
    "for badge_name in stale_badges:\n",
    "    os.remove(f\"{badge_dir}/{badge_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cc41fb",
   "metadata": {},
   "source": [
    "### Try to determine the URL of the COACCH metadata file for each hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_urls = []\n",
    "for hit in hits:\n",
    "    print(f\"-------- ID: {hit['id']}\")\n",
    "    files = hit['files']\n",
    "    meta_url = None\n",
    "    for f in files:\n",
    "        link = f['links']['self']\n",
    "        if link.lower().find(\"metadata\") >= 0 or link.lower().find(\"meta%20data\") >= 0:\n",
    "            if link.lower().find(\"datasetwide\") >= 0:\n",
    "                # prefer a dataset wide metadata file\n",
    "                meta_url = link\n",
    "                print(f\"{link} <-- preferred metadata\")\n",
    "                break\n",
    "            assert meta_url is None # data set should have only one meta data file\n",
    "            meta_url = link\n",
    "            print(f\"{link} <-- metadata?\")\n",
    "        else:\n",
    "            print(f\"{link}\")\n",
    "    if meta_url is None:\n",
    "        print(f\"WARNING: data set {hit['id']} includes no obvious metadata file!\")\n",
    "    else:\n",
    "        hit['coacch'] = {} # add empty dict to hold COACCH-specifics\n",
    "        hit['coacch']['meta_url'] = meta_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb484c16",
   "metadata": {},
   "source": [
    "### Retrieve COACCH metadata files for the hits\n",
    "\n",
    "Store as an in-memory binary-file-like object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in hits:\n",
    "    if 'coacch' in hit and 'meta_url' in hit['coacch']:\n",
    "        r = reget(hit['coacch']['meta_url'])\n",
    "        hit['coacch']['metadata'] = io.BytesIO(r.content)\n",
    "print(\"Done retrieving COACCH metadata for hits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cac7c1",
   "metadata": {},
   "source": [
    "### Special handling: Retrieve COACCH metadata for 4733499"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c62a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in hits:\n",
    "    if hit['id'] == 4733499:\n",
    "        hit4733499 = hit\n",
    "with open(\"../bad_metadata/COACCH_MetaData_BC3_WP4.csv\", \"rb\") as f:\n",
    "    contents = f.read()\n",
    "    hit4733499['coacch'] = {}\n",
    "    hit4733499['coacch']['metadata'] = io.BytesIO(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3751f2",
   "metadata": {},
   "source": [
    "### Special handling: Retrieve COACCH metadata for 5541894"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca503a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in hits:\n",
    "    if hit['id'] == 5541894:\n",
    "        hit5541894 = hit\n",
    "with open(\"../bad_metadata/COACCH_MetaData_energy_demand_cleaned_up.csv\", \"rb\") as f:\n",
    "    contents = f.read()\n",
    "    hit5541894['coacch'] = {}\n",
    "    hit5541894['coacch']['metadata'] = io.BytesIO(contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34679dc3",
   "metadata": {},
   "source": [
    "### For each hit, check and convert the metadata CSV to dictionaries for each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c92024",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in hits:\n",
    "    print(f\"-------- ID: {hit['id']}\")\n",
    "    if 'coacch' in hit and 'metadata' in hit['coacch']:\n",
    "        metadata = hit['coacch']['metadata']\n",
    "        encoding = guess_encoding(metadata)\n",
    "        try:\n",
    "            metadata.seek(0)\n",
    "            metadata_chunk = str(metadata.read(8000), encoding)\n",
    "        except UnicodeDecodeError as error:\n",
    "            try:\n",
    "                metadata.seek(0)\n",
    "                encoding = 'Windows-1252'\n",
    "                metadata_chunk = str(metadata.read(8000), encoding)\n",
    "            except UnicodeDecodeError as error:\n",
    "                metadata.seek(0)\n",
    "                encoding = 'utf-8'\n",
    "                metadata_chunk = str(metadata.read(8000), encoding)\n",
    "        metadata.seek(0)\n",
    "        if csv.Sniffer().has_header(metadata_chunk):\n",
    "            dialect = csv.Sniffer().sniff(metadata_chunk)\n",
    "            reader = csv.DictReader(metadata, dialect=dialect, encoding=encoding)\n",
    "            rows = []\n",
    "            for row in reader:\n",
    "                rows.append(row)\n",
    "            # Special handling for dataset 5541894: want the 2nd of 2 rows\n",
    "            if hit['id'] == 5541894:\n",
    "                rows.reverse()\n",
    "            hit['coacch']['metadata_rows'] = rows\n",
    "            print(f\"Converted {len(rows)} row{'s' if len(rows) > 1 else ''} of metadata\")\n",
    "        else:\n",
    "            print(f\"WARNING: metadata of dataset https://zenodo.org/record/{hit['id']} has no CSV header. The metadata URL is {hit['coacch']['meta_url']}\")\n",
    "    else:\n",
    "        print(\"WARNING: metadata absent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c330e",
   "metadata": {},
   "source": [
    "### Check metadata column headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f359b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in hits:\n",
    "    print(f\"-------- ID: {hit['id']}\")\n",
    "    if 'coacch' in hit and 'metadata_rows' in hit['coacch']:\n",
    "        rows = hit['coacch']['metadata_rows']\n",
    "        headers = rows[0].keys()\n",
    "        print(headers)\n",
    "        template_headers = ['Name', 'Entry date', 'Dataset version', 'Author/Contact person', 'Short description', 'Partner', 'Model type/method', 'Model', 'Model version', 'Documentation', 'Sector', 'Keywords', 'SSP', 'RCP', 'GCM', 'Variables and units', 'Time start', 'Time end', 'Time resolution', 'Spatial coverage', 'Spatial resolution unit Europe', 'Spatial resolution Rest of World', 'Spatial projection', 'Data type', 'File format', 'Recommended citation', 'Other comments']\n",
    "        for t in template_headers:\n",
    "            if t not in headers:\n",
    "                print(f\"WARNING: required header '{t}' is absent.\")\n",
    "        for h in headers:\n",
    "            if  h not in template_headers:\n",
    "                print(f\"WARNING: header '{h}' is present but not required.\")\n",
    "    else:\n",
    "        print(\"No metadata rows were converted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb93ca9",
   "metadata": {},
   "source": [
    "### Remove spurious line feeds from COACCH metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec01e4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for hit in hits:\n",
    "    if 'coacch' in hit and 'metadata_rows' in hit['coacch']:\n",
    "        cm = hit['coacch']['metadata_rows'][0]\n",
    "        cm['RCP'] = cm['RCP'].replace('\\n', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b6cd8d",
   "metadata": {},
   "source": [
    "### Produce a reStructuredText page for each hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5898976e",
   "metadata": {},
   "outputs": [],
   "source": [
    "page_dir = f\"../docs/{params['type']}s\"\n",
    "if not os.path.exists(page_dir):\n",
    "    os.makedirs(page_dir)\n",
    "# List already present pages\n",
    "stale_pages = os.listdir(page_dir)\n",
    "\n",
    "# Generate ReST pages and write them to the page directory\n",
    "for hit in hits:\n",
    "    print(f\"Producing reStructuredText for hit {hit['id']}: {hit['metadata']['title']}\")\n",
    "    page_name = rest_hit(hit, page_dir)\n",
    "    if page_name in stale_pages:\n",
    "        # Page is not stale\n",
    "        stale_pages.remove(page_name)\n",
    "\n",
    "# Remove any pages that are no longer required\n",
    "for page_name in stale_pages:\n",
    "    os.remove(f\"{page_dir}/{page_name}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54664488",
   "metadata": {},
   "source": [
    "### Add datasets to their respective class pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1aedb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect the IDs of the hits\n",
    "ids = [hit['id'] for hit in hits]\n",
    "# set up a dictionary to keep track of which IDs were written\n",
    "written = {}\n",
    "\n",
    "for c in classes:\n",
    "    page_path = f\"../docs/classes/{c}.rst\"\n",
    "    # check that the IDs in the class were returned by the query\n",
    "    for id in classes[c]:\n",
    "        if id not in ids:\n",
    "            print(f\"WARNING: no hit with ID {id} in class '{c}' was returned by the Zenodo query!\")\n",
    "    # read the reStructuredText page of the class\n",
    "    with open(page_path, \"r\", encoding = 'utf-8') as class_rst:\n",
    "        lines = class_rst.readlines()\n",
    "    # find the toctree\n",
    "    i = 0\n",
    "    while lines[i].find(\".. toctree::\") < 0:\n",
    "        i += 1\n",
    "    # find the start of the ToC entries\n",
    "    while lines[i] != '\\n':\n",
    "        i += 1\n",
    "    i += 1\n",
    "    assert i > 2\n",
    "    start = i\n",
    "    # remove ToC entries\n",
    "    while i < len(lines) and lines[i] != '\\n':\n",
    "        lines.pop(i)\n",
    "    # add new ToC entries\n",
    "    for id in reversed([hit['id'] for hit in hits]):\n",
    "        if id in classes[c] or c =='other' and id not in written:\n",
    "            written[id] = True\n",
    "            lines.insert(start, f\"   ../datasets/{id}\\n\")\n",
    "    # write the reStructuredText page of the class\n",
    "    with open(page_path, \"w\", encoding = 'utf-8', newline = '\\n') as class_rst:\n",
    "        class_rst.writelines(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb0765e",
   "metadata": {},
   "source": [
    "### Show aggregations (aggregate data over all query hits, presumably)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc5125a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml.dump(aggregations))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059701e3",
   "metadata": {},
   "source": [
    "### Dump a hit as YAML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe13ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(yaml.dump(hits[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
